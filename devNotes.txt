
QUESTIONS:

Does the grammar allow for multi digit numbers? - NO
---------------------------------------------------------------------------------------------------------

Test cases:
/*lex without spaces*/
{intaa=1print(a)booleanbb=true}$

/*multiple strings with some missing quotes*/
{intaa=1print("hello world)booleanbb=true}{intaa=1print("hello world)booleanbb=true}$
---------------------------------------------------------------------------------------------------------

Feb 17th

to do:
	-verify order or toxenRegex array so longest match is enforced
	-remove /b word boundary so lex can uccur without spaes properly
	-add some boolFlags like inBrace, inQuotes, inBlock(?)
	-implement warning handling

Strings are not lexemmes so I should remove it from the regex, instead detect quotes and identify each piece as a char or space then anything else until next quote as invalid symbols

Lets treat comments like strings in that we should recognize the start and end seperately and anything in between will be transmuted to a comment
we can even skip looping through regex def while inComment is true

anything inside a comment doesn't get added to tokens[] so I can;t look at the last token and check inComment as a way to check for unterminated comments. We'll need to handle this flag some other way. What if I looked for com_start and see if I ever get com_end?

Wait that still doesnt work since com start and end are not added to tokens[]

Ok but it does work for quotes

---------------------------------------------------------------------------------------------------------

Feb 12th
2pm

The site is live, lexer is running on input code and displaying an output. Enums have been properly adjusted but there still may be some work to do. Currently we are not handling mutliple programs properly and there is no logic at all to handle warnings, only errors.
Goal is to continue testing and adjusting the logic in index.ts formatTokens() to handle this.
After that we'll make sure that all of Alan's test cases return the expected output. Then we can use crazier test cases and continue imporving code
	todo:
		handle mulitple programs in one input
		recognize warnings
		add $ (EOP) if none is present
		change text appearance for warnings and errors
---------------------------------------------------------------------------------------------------------

Feb 11

previous work was mostly wrong but rereading the chapter and instructions I understand better

**New Branch** - newStruct

Structure of project changes to use browser and remove node-modules from git

lexer directory removed and lexer.ts and index.ts places in source folder

Now I'll move the enum I created earlier (and backed up locally) to lexer.ts

lexer.ts should also do the following:

	define token structure (type, value, position (line and column?))
	distinguish between tokens with RegEx formulas
	take and input (test code) and 'tokenize' what it gets. ie use the structure and regex to assign what it reads as valid or invalid tokens
	find errors and warnings
	log the output accordingly

index.ts

	create JS for index.html.

---------------------------------------------------------------------------------------------------------
Feb 2

Commit 0:
project structure intailaized
there might be issues with where JS code generates
how to implement dist folder?

Commit 1: 
file reader method set up and log message works properly

Commit 2:
token list created as enum in src/lexer/token.ts
is this token list complete? 
Do I need to add digits and charecters?

Goal:
Check for valid keywords, identifiers, symbols, digits, charecters

steps
Charecter has
	-position (Line and number)
	-content
	-parents
	-expected partner (open brace expects closed brace, quotations, etc)
	
Token has
	-start position
	-end position
	-content
	
	
We need to read charecters, sorth them into tokens, and check their validity

test cases will be in local folder but can be any name or extension
---------------------------------------------------------------------------------------------------------
